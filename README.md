# bigdata-crypto-project
Proxy Big Data centralisant les appels API crypto (CoinGecko) via pipeline Kafka â†’ Elasticsearch â†’ Kibana.


# ğŸš€ Crypto Tracking Application - Projet Big Data Temps RÃ©el

## ğŸ“‹ Contexte du Projet

Cette application centralise la rÃ©cupÃ©ration des taux de cryptomonnaies pour optimiser les coÃ»ts d'API. Au lieu que chaque Ã©quipe appelle directement l'API CoinGecko, notre solution :

- âœ… RÃ©cupÃ¨re les donnÃ©es crypto via l'API CoinGecko
- âœ… Publie les donnÃ©es en temps rÃ©el sur Kafka
- âœ… Stocke les donnÃ©es dans Elasticsearch
- âœ… Visualise les donnÃ©es via Kibana

Les Ã©quipes internes peuvent alors consommer les donnÃ©es depuis Kafka sans accÃ©der directement Ã  l'API externe.

## ğŸ—ï¸ Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ CoinGecko â”‚â”€â”€â”€â–¶â”‚ Kafka â”‚â”€â”€â”€â–¶â”‚ Elasticsearch â”‚
â”‚ API â”‚ â”‚ (crypto-data) â”‚ â”‚ (crypto-prices)â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚ â”‚ â”‚
â”‚ Producer â”‚ â”‚ Kibana â”‚
â”‚ (crypto_api) â”‚ â”‚ (Dashboards) â”‚
â”‚ â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚
â”‚ Consumer â”‚
â”‚(crypto_consumer)â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


## ğŸ“ Structure du Projet

bigdata-crypto-project/
â”‚
â”œâ”€â”€ README.md # Documentation du projet
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â”œâ”€â”€ .gitignore # Fichiers Ã  ignorer
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ crypto_api.py # Producer Kafka - RÃ©cupÃ©ration API
â”‚ â”œâ”€â”€ crypto_consumer.py # Consumer Kafka - Indexation ES
â”‚ â””â”€â”€ config.py # Configuration centralisÃ©e
â”‚
â”œâ”€â”€ docker/
â”‚ â””â”€â”€ docker-compose.yml # Stack ELK + Kafka
â”‚
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ installation.md # Guide d'installation
â”‚ â””â”€â”€ screenshots/ # Captures d'Ã©cran
â”‚
â””â”€â”€ scripts/
â”œâ”€â”€ start_services.sh # DÃ©marrage des services
â”œâ”€â”€ create_topics.sh # CrÃ©ation topics Kafka
â””â”€â”€ setup_kibana.sh # Configuration Kibana


## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | Version | RÃ´le |
|-------------|---------|------|
| **Python** | 3.9+ | DÃ©veloppement application |
| **Apache Kafka** | 2.8.0 | Message broker temps rÃ©el |
| **Elasticsearch** | 8.11.0 | Base de donnÃ©es NoSQL |
| **Kibana** | 8.11.0 | Visualisation des donnÃ©es |
| **Docker** | - | Conteneurisation |

## ğŸ“¦ DÃ©pendances Python

```txt
kafka-python==2.0.2
elasticsearch==8.11.0
requests==2.31.0
python-dotenv==1.0.0
schedule==1.2.0

âš™ï¸ Installation et Configuration
1. PrÃ©requis
# Installer Python 3.9+
# Installer Docker et Docker Compose
# VÃ©rifier les ports disponibles : 9092, 9200, 5601

2. Cloner le Projet
git clone https://github.com/votre-username/bigdata-crypto-project.git
cd bigdata-crypto-project

3. Environnement Virtuel
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

4. Installer les DÃ©pendances
pip install -r requirements.txt

5. DÃ©marrer les Services
# DÃ©marrer Kafka
cd /opt/homebrew/bin
./kafka-server-start /opt/homebrew/etc/kafka/server.properties

# Nouveau terminal - DÃ©marrer Elasticsearch
elasticsearch

# Nouveau terminal - DÃ©marrer Kibana
kibana

6. CrÃ©er le Topic Kafka
kafka-topics --create --topic crypto-data --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

ğŸš€ Utilisation
DÃ©marrage de l'Application
1. Lancer le Producer (Terminal 1)
cd bigdata-crypto-project
source venv/bin/activate
python crypto_api.py

RÃ©sultat attendu :

ğŸš€ DÃ©marrage rÃ©cupÃ©ration crypto toutes les 60 secondes...
ğŸ“Š RÃ©cupÃ©ration donnÃ©es - 14:38:04
âœ… EnvoyÃ©: Bitcoin - $105330
âœ… EnvoyÃ©: Ethereum - $2624.06
âœ… 50 cryptos envoyÃ©es vers Kafka
â³ Attente 60 secondes...

2. Lancer le Consumer (Terminal 2)
cd bigdata-crypto-project
source venv/bin/activate
python crypto_consumer.py

RÃ©sultat attendu :

ğŸš€ Consumer Kafka dÃ©marrÃ©, en attente de messages...
ğŸ“Š Traitement: Bitcoin - $105330.0 - 2025-01-07 14:38:04
âœ… DonnÃ©es envoyÃ©es vers Elasticsearch

3. VÃ©rifier l'Indexation
curl "localhost:9200/_cat/indices?v"

RÃ©sultat attendu :

health status index         docs.count store.size
yellow open   crypto-prices        87     42.9kb

AccÃ¨s aux Interfaces
Service	URL	Description
Kibana	http://localhost:5601	Dashboards et visualisations
Elasticsearch	http://localhost:9200	API REST pour les donnÃ©es
ğŸ“Š Configuration Kibana
1. CrÃ©er un Data View
Ouvrir Kibana : http://localhost:5601
Menu â†’ Stack Management â†’ Data Views
Create data view
Name : crypto-prices
Index pattern : crypto-prices
Timestamp field : timestamp
2. Dashboards RecommandÃ©s
ğŸ“ˆ Prix en Temps RÃ©el
Type : Line chart
X-axis : timestamp
Y-axis : price
Split series : symbol
ğŸ† Top 10 Cryptos
Type : Horizontal bar
Y-axis : symbol
X-axis : Average of price
ğŸ“‹ Tableau de DonnÃ©es
Type : Data table
Colonnes : name, symbol, price, market_cap
ğŸ“ˆ DonnÃ©es CollectÃ©es
Structure des Documents Elasticsearch
{
  "_index": "crypto-prices",
  "_source": {
    "symbol": "BTC",
    "name": "Bitcoin",
    "price": 105330.0,
    "market_cap": 2084329845234,
    "volume_24h": 28456789123,
    "change_24h": 2.45,
    "timestamp": "2025-01-07T14:38:04.123456"
  }
}

FrÃ©quence de Collecte
â±ï¸ Intervalle : 60 secondes
ğŸ“Š Cryptos suivies : Top 50 par market cap
ğŸ”„ Mode : Temps rÃ©el continu
ğŸ§ª Tests et Validation
VÃ©rification du Pipeline
1. Test Producer
# VÃ©rifier les messages Kafka
kafka-console-consumer --bootstrap-server localhost:9092 --topic crypto-data --from-beginning

2. Test Elasticsearch
# Compter les documents
curl "localhost:9200/crypto-prices/_count"

# Voir un Ã©chantillon
curl "localhost:9200/crypto-prices/_search?size=5" | jq

3. Test Consumer
# Logs attendus
tail -f consumer.log

ğŸš¨ DÃ©pannage
ProblÃ¨mes FrÃ©quents
Kafka ne dÃ©marre pas
# VÃ©rifier le port 9092
netstat -an | grep 9092

# Nettoyer les logs Kafka
rm -rf /opt/homebrew/var/lib/kafka-logs/*

Elasticsearch inaccessible
# VÃ©rifier le status
curl localhost:9200/_cluster/health

# RedÃ©marrer si nÃ©cessaire
brew services restart elasticsearch

Pas de donnÃ©es dans Kibana
# VÃ©rifier l'index
curl "localhost:9200/crypto-prices/_search?size=1"

# RecrÃ©er le data view si besoin

Messages d'Erreur Courants
Erreur	Solution
Connection refused 9092	DÃ©marrer Kafka
Index not found	VÃ©rifier le consumer
No data view	CrÃ©er le data view dans Kibana

ğŸ‘¨â€ğŸ’» DÃ©veloppeur
Nom : Steven CODJO
Projet : Application Big Data Temps RÃ©el
Date : Janvier 2025

ğŸ“ Licence
Ce projet est dÃ©veloppÃ© dans le cadre d'un exercice acadÃ©mique.

ğŸ¯ Commandes de DÃ©marrage Rapide
# Terminal 1 - Producer
cd bigdata-crypto-project && source venv/bin/activate && python crypto_api.py

# Terminal 2 - Consumer  
cd bigdata-crypto-project && source venv/bin/activate && python crypto_consumer.py

# Terminal 3 - Monitoring
watch -n 5 'curl -s "localhost:9200/crypto-prices/_count" | jq'
